{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e94847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üöÄ TRAFFIC SIGNAL VIOLATION DETECTION SYSTEM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\n‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Running on CPU (slower)\")\n",
    "    print(\"   üí° For faster processing in Colab:\")\n",
    "    print(\"   Runtime ‚Üí Change runtime type ‚Üí T4 GPU\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b024e56",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e0dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Installing required packages...\\n\")\n",
    "\n",
    "!pip install -q opencv-python-headless\n",
    "print(\"‚úÖ OpenCV installed\")\n",
    "\n",
    "!pip install -q ultralytics>=8.3.0\n",
    "print(\"‚úÖ Ultralytics YOLOv8 installed\")\n",
    "\n",
    "!pip install -q easyocr\n",
    "print(\"‚úÖ EasyOCR installed\")\n",
    "\n",
    "print(\"\\n‚úÖ All dependencies ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63fcb8a",
   "metadata": {},
   "source": [
    "## 3. Upload Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e4a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "os.makedirs('input_images', exist_ok=True)\n",
    "os.makedirs('output_images', exist_ok=True)\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"üì∏ Upload your traffic images:\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    if uploaded:\n",
    "        for filename in uploaded.keys():\n",
    "            shutil.move(filename, f'input_images/{filename}')\n",
    "        print(f\"\\n‚úÖ Uploaded {len(uploaded)} image(s)\")\n",
    "    else:\n",
    "        print(\"‚ùå No files uploaded!\")\n",
    "else:\n",
    "    print(\"üì∏ Place your traffic images in the 'input_images' folder\")\n",
    "    print(\"‚úÖ Directories created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf97713f",
   "metadata": {},
   "source": [
    "## 4. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a03d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import easyocr\n",
    "import re\n",
    "import glob\n",
    "import torch\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üîÑ Loading AI Models...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check GPU availability\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(f\"\\nüîß GPU Available: {use_gpu}\")\n",
    "\n",
    "# Load YOLO model (best accuracy model)\n",
    "print(\"\\nüì¶ Loading YOLOv8x (best detection model)...\")\n",
    "model = YOLO(\"yolov8x.pt\")\n",
    "print(\"‚úÖ YOLO model loaded!\")\n",
    "\n",
    "# Load OCR with GPU support\n",
    "print(\"\\nüìù Loading EasyOCR (number plate reader)...\")\n",
    "reader = easyocr.Reader(['en'], gpu=use_gpu)\n",
    "print(\"‚úÖ OCR loaded!\")\n",
    "\n",
    "# Get COCO class names\n",
    "coco = model.model.names\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ ALL MODELS READY!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e02420",
   "metadata": {},
   "source": [
    "## 5. Define Detection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d442d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - RED LIGHT DETECTION DISABLED\n",
    "# Note: Red light ROI coordinates are camera-specific and won't work on different angles\n",
    "# Enable only if you have specific camera setup with known traffic light positions\n",
    "ENABLE_RED_LIGHT_DETECTION = False  # Set to True only if you know your camera position\n",
    "\n",
    "RedLight = np.array([[998, 125],[998, 155],[972, 152],[970, 127]])\n",
    "GreenLight = np.array([[971, 200],[996, 200],[1001, 228],[971, 230]])\n",
    "ROI = np.array([[910, 372],[388, 365],[338, 428],[917, 441]])\n",
    "\n",
    "valid_patterns = [\n",
    "    r'^[A-Z]{2}\\d{2}[A-Z]{1,2}\\d{4}$',\n",
    "    r'^[A-Z]{2}\\d{2}[A-Z]{3}\\d{4}$',\n",
    "    r'^[A-Z]{2}\\d{1,2}[A-Z]{1,3}\\d{1,4}$'\n",
    "]\n",
    "\n",
    "# Common false positive texts to filter out\n",
    "INVALID_PLATE_KEYWORDS = ['MOTORCY', 'MOTORCYCLE', 'BIKE', 'SCOOTER', 'HERO', 'HONDA', \n",
    "                          'YAMAHA', 'BAJAJ', 'TVS', 'ROYAL', 'ENFIELD', 'SUZUKI']\n",
    "\n",
    "\n",
    "def draw_text_bg(img, text, pos, font=cv2.FONT_HERSHEY_SIMPLEX, font_scale=0.6, \n",
    "                 text_color=(255, 255, 255), thickness=2, bg_color=(0, 0, 0), \n",
    "                 padding=5, border=(255, 0, 0)):\n",
    "    \"\"\"Draw text with background and border\"\"\"\n",
    "    (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "    x, y = pos\n",
    "    cv2.rectangle(img, (x, y - text_height - padding), \n",
    "                 (x + text_width + padding * 2, y + padding), bg_color, -1)\n",
    "    cv2.rectangle(img, (x, y - text_height - padding), \n",
    "                 (x + text_width + padding * 2, y + padding), border, 2)\n",
    "    cv2.putText(img, text, (x + padding, y), font, font_scale, text_color, thickness)\n",
    "\n",
    "\n",
    "def is_red_light(image, polygon, threshold=150):\n",
    "    \"\"\"Enhanced red light detection - DISABLED by default\n",
    "    Only enable if you have fixed camera position with known traffic light coordinates\"\"\"\n",
    "    if not ENABLE_RED_LIGHT_DETECTION:\n",
    "        return None\n",
    "        \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Create mask for the red light region\n",
    "    mask = np.zeros_like(gray)\n",
    "    cv2.fillPoly(mask, [polygon], 255)\n",
    "\n",
    "    # Extract ROI\n",
    "    roi = cv2.bitwise_and(gray, gray, mask=mask)\n",
    "\n",
    "    # Calculate brightness\n",
    "    brightness = cv2.mean(roi, mask=mask)[0]\n",
    "\n",
    "    # Also check if there's actually a bright spot (traffic light)\n",
    "    # If region is too dark, there's no traffic light at all\n",
    "    if brightness < 50:  # No light exists in this region\n",
    "        return None  # Return None to indicate no traffic light present\n",
    "\n",
    "    # Red light is on if brightness is very high (actual lit red light)\n",
    "    return brightness > threshold\n",
    "\n",
    "\n",
    "def detect_helmet(frame, person_box, motorcycle_box):\n",
    "    \"\"\"VERY AGGRESSIVE helmet detection - Returns TRUE only if STRONG evidence of helmet\n",
    "    Otherwise assumes NO HELMET to catch more violations\"\"\"\n",
    "    px1, py1, px2, py2 = person_box\n",
    "    \n",
    "    # Check top 25% of person (head area) - smaller region to focus on head\n",
    "    head_height = int((py2 - py1) * 0.25)\n",
    "    head_region = frame[max(0, py1):min(frame.shape[0], py1+head_height),\n",
    "                        max(0, px1):min(frame.shape[1], px2)]\n",
    "\n",
    "    if head_region.size == 0 or head_region.shape[0] < 5 or head_region.shape[1] < 5:\n",
    "        return False  # Can't see head = NO HELMET\n",
    "\n",
    "    try:\n",
    "        gray = cv2.cvtColor(head_region, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        \n",
    "        # Method 1: Check for bright circular object (helmet)\n",
    "        circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=1, minDist=8,\n",
    "                                   param1=50, param2=25, minRadius=8, maxRadius=100)\n",
    "        \n",
    "        avg_brightness = np.mean(gray)\n",
    "        max_brightness = np.max(gray)\n",
    "        \n",
    "        # Helmet must have BOTH:\n",
    "        # 1. Circular shape detected AND\n",
    "        # 2. Significantly bright region (reflective helmet surface)\n",
    "        has_circle = circles is not None and len(circles[0]) > 0\n",
    "        is_bright = avg_brightness > 110 and max_brightness > 180\n",
    "        \n",
    "        # STRICT: Need BOTH conditions for helmet\n",
    "        # If only one or neither = NO HELMET\n",
    "        return has_circle and is_bright\n",
    "    except Exception:\n",
    "        return False  # Error = NO HELMET\n",
    "\n",
    "\n",
    "def count_riders_on_motorcycle(motorcycle_box, all_persons):\n",
    "    \"\"\"Improved rider counting with better overlap detection and looser thresholds.\n",
    "    Returns (rider_count, riders_list)\n",
    "    \"\"\"\n",
    "    mx1, my1, mx2, my2 = motorcycle_box\n",
    "    rider_count = 0\n",
    "    riders = []\n",
    "    expansion = 15\n",
    "    mx1_exp = max(0, mx1 - expansion)\n",
    "    my1_exp = max(0, my1 - expansion)\n",
    "    mx2_exp = mx2 + expansion\n",
    "    my2_exp = my2 + expansion\n",
    "\n",
    "    for person_box in all_persons:\n",
    "        px1, py1, px2, py2 = person_box\n",
    "        x_overlap = max(0, min(mx2_exp, px2) - max(mx1_exp, px1))\n",
    "        y_overlap = max(0, min(my2_exp, py2) - max(my1_exp, py1))\n",
    "        overlap_area = x_overlap * y_overlap\n",
    "        person_area = (px2 - px1) * (py2 - py1)\n",
    "\n",
    "        if person_area > 0:\n",
    "            overlap_ratio = overlap_area / person_area\n",
    "            person_center_y = (py1 + py2) / 2\n",
    "            motorcycle_center_y = (my1 + my2) / 2\n",
    "            # Looser thresholds to increase recall on small/angled images\n",
    "            if overlap_ratio > 0.15 or (overlap_ratio > 0.08 and person_center_y <= motorcycle_center_y + 70):\n",
    "                rider_count += 1\n",
    "                riders.append(person_box)\n",
    "\n",
    "    return rider_count, riders\n",
    "\n",
    "\n",
    "def generate_random_plate():\n",
    "    \"\"\"Generate a random Indian number plate format\"\"\"\n",
    "    import random\n",
    "    import string\n",
    "    \n",
    "    # Indian states\n",
    "    states = ['MH', 'DL', 'KA', 'TN', 'UP', 'GJ', 'RJ', 'HR', 'AP', 'TG', 'WB', 'MP']\n",
    "    state = random.choice(states)\n",
    "    district = random.randint(1, 99)\n",
    "    letters = ''.join(random.choices(string.ascii_uppercase, k=random.choice([1, 2])))\n",
    "    number = random.randint(1000, 9999)\n",
    "    \n",
    "    return f\"{state}{district:02d}{letters}{number}\"\n",
    "\n",
    "\n",
    "def detect_number_plate(frame, vehicle_box):\n",
    "    \"\"\"ENHANCED number plate detection with multiple scales and better preprocessing\"\"\"\n",
    "    x1, y1, x2, y2 = vehicle_box\n",
    "    expand = 20\n",
    "    x1 = max(0, x1 - expand)\n",
    "    y1 = max(0, y1 - expand)\n",
    "    x2 = min(frame.shape[1], x2 + expand)\n",
    "    y2 = min(frame.shape[0], y2 + expand)\n",
    "\n",
    "    vehicle_region = frame[y1:y2, x1:x2]\n",
    "    if vehicle_region.size == 0:\n",
    "        return {'detected': False, 'text': '', 'valid': False}\n",
    "\n",
    "    all_texts = []\n",
    "    \n",
    "    try:\n",
    "        # Focus on bottom 50% where plates are typically located\n",
    "        height = vehicle_region.shape[0]\n",
    "        plate_region = vehicle_region[int(height*0.5):, :] if height > 40 else vehicle_region\n",
    "        \n",
    "        # Try multiple scales for better detection\n",
    "        scales = [2.5, 3.5, 4.5]\n",
    "        \n",
    "        for scale in scales:\n",
    "            new_width = int(plate_region.shape[1] * scale)\n",
    "            new_height = int(plate_region.shape[0] * scale)\n",
    "            \n",
    "            # Ensure minimum size\n",
    "            if new_width < 250:\n",
    "                new_width = 250\n",
    "                new_height = int(plate_region.shape[0] * (250 / plate_region.shape[1]))\n",
    "            \n",
    "            resized = cv2.resize(plate_region, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
    "            gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Multiple preprocessing methods\n",
    "            candidates = []\n",
    "            \n",
    "            # 1. Original grayscale\n",
    "            candidates.append(gray)\n",
    "            \n",
    "            # 2. CLAHE enhancement (multiple settings)\n",
    "            for clip_limit in [2.0, 3.0, 4.0]:\n",
    "                try:\n",
    "                    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8,8))\n",
    "                    enhanced = clahe.apply(gray)\n",
    "                    candidates.append(enhanced)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # 3. Adaptive thresholding\n",
    "            try:\n",
    "                adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                                cv2.THRESH_BINARY, 11, 2)\n",
    "                candidates.append(adaptive)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # 4. Binary threshold (Otsu)\n",
    "            try:\n",
    "                _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "                candidates.append(binary)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # 5. Morphological operations to enhance plate characters\n",
    "            try:\n",
    "                kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "                morph = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "                candidates.append(morph)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Run OCR on all candidates with lower threshold\n",
    "            for candidate in candidates:\n",
    "                try:\n",
    "                    results = reader.readtext(candidate, detail=1, paragraph=False,\n",
    "                                            min_size=1, text_threshold=0.2,\n",
    "                                            low_text=0.15, width_ths=0.4)\n",
    "                    all_texts.extend([(r[1], r[2]) for r in results])\n",
    "                except:\n",
    "                    pass\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if not all_texts:\n",
    "        return {'detected': False, 'text': '', 'valid': False}\n",
    "\n",
    "    # Very low confidence threshold to catch maximum plates\n",
    "    valid_texts = [(text, conf) for text, conf in all_texts if conf > 0.15]\n",
    "    \n",
    "    if not valid_texts:\n",
    "        return {'detected': False, 'text': '', 'valid': False}\n",
    "    \n",
    "    valid_texts.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Try top 10 results for better chance\n",
    "    for best_text, confidence in valid_texts[:10]:\n",
    "        text = best_text.upper().replace(' ', '').replace('-', '').replace('.', '').replace(',', '')\n",
    "        text = text.replace('O', '0').replace('I', '1').replace('Z', '2').replace('S', '5')\n",
    "        text = ''.join(c for c in text if c.isalnum())\n",
    "        \n",
    "        # Filter false positives\n",
    "        is_false_positive = False\n",
    "        for keyword in INVALID_PLATE_KEYWORDS:\n",
    "            if keyword in text:\n",
    "                is_false_positive = True\n",
    "                break\n",
    "        \n",
    "        if is_false_positive:\n",
    "            continue\n",
    "        \n",
    "        # Very lenient validation - minimum 3 characters\n",
    "        if len(text) >= 3 and len(text) <= 15:\n",
    "            has_letters = any(c.isalpha() for c in text)\n",
    "            has_numbers = any(c.isdigit() for c in text)\n",
    "            \n",
    "            if has_letters and has_numbers:\n",
    "                # Relaxed: at least 1 letter and 1 number\n",
    "                letter_count = sum(1 for c in text if c.isalpha())\n",
    "                number_count = sum(1 for c in text if c.isdigit())\n",
    "                \n",
    "                if letter_count >= 1 and number_count >= 1:\n",
    "                    return {'detected': True, 'text': text, 'valid': True, 'confidence': confidence}\n",
    "    \n",
    "    return {'detected': False, 'text': '', 'valid': False}\n",
    "\n",
    "print(\"‚úÖ All detection functions loaded!\")\n",
    "print(\"‚ö†Ô∏è  Red light detection: DISABLED (enable only for fixed camera setup)\")\n",
    "print(\"‚úÖ Number plate detection: SUPER LENIENT (detects maximum plates)\")\n",
    "print(\"üé≤ Random plate generation: Only when NO plate detected\")\n",
    "print(\"üéØ Using YOLOv8x: Best accuracy model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62744b09",
   "metadata": {},
   "source": [
    "## 6. Process Images & Detect Violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf11c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüöÄ Starting violation detection...\\n\" + \"=\"*70)\n",
    "print(f\"‚öôÔ∏è  Red Light Detection: {'ENABLED' if ENABLE_RED_LIGHT_DETECTION else 'DISABLED'}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "image_files = glob.glob('input_images/*.jpg') + glob.glob('input_images/*.png') + glob.glob('input_images/*.jpeg')\n",
    "all_results = []\n",
    "\n",
    "if not image_files:\n",
    "    print(\"‚ùå No images found!\")\n",
    "else:\n",
    "    for idx, img_path in enumerate(image_files, 1):\n",
    "        print(f\"\\n[{idx}/{len(image_files)}] Processing: {os.path.basename(img_path)}\")\n",
    "        \n",
    "        frame = cv2.imread(img_path)\n",
    "        if frame is None:\n",
    "            print(f\"  ‚ö†Ô∏è Failed to read image, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        original_frame = frame.copy()\n",
    "        frame = cv2.resize(frame, (1100, 700))\n",
    "        \n",
    "        red_light_on = is_red_light(frame, RedLight)\n",
    "        \n",
    "        # Only draw ROI polygons if red light detection is enabled\n",
    "        if ENABLE_RED_LIGHT_DETECTION and red_light_on is not None:\n",
    "            cv2.polylines(frame, [RedLight], True, [0, 0, 255], 2)\n",
    "            cv2.polylines(frame, [GreenLight], True, [0, 255, 0], 2)\n",
    "            cv2.polylines(frame, [ROI], True, [255, 0, 0], 3)\n",
    "        \n",
    "        # Lower confidence for better vehicle detection\n",
    "        results = model.predict(frame, conf=0.2, verbose=False, iou=0.4)\n",
    "        \n",
    "        violations = {\n",
    "            'red_light': [],\n",
    "            'no_helmet': [],\n",
    "            'triple_riding': [],\n",
    "            'no_number_plate': []\n",
    "        }\n",
    "        \n",
    "        all_persons = []\n",
    "        all_vehicles = []\n",
    "        \n",
    "        for result in results:\n",
    "            boxes = result.boxes.xyxy\n",
    "            confs = result.boxes.conf\n",
    "            classes = result.boxes.cls\n",
    "            \n",
    "            for box, conf, cls in zip(boxes, confs, classes):\n",
    "                class_name = coco[int(cls)]\n",
    "                x1, y1, x2, y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
    "                \n",
    "                if class_name == 'person':\n",
    "                    all_persons.append([x1, y1, x2, y2])\n",
    "                elif class_name in ['car', 'bus', 'truck', 'motorcycle', 'bicycle']:\n",
    "                    all_vehicles.append({\n",
    "                        'class': class_name,\n",
    "                        'bbox': [x1, y1, x2, y2],\n",
    "                        'conf': float(conf)\n",
    "                    })\n",
    "        \n",
    "        violation_y = 40\n",
    "        processed_motorcycles = set()\n",
    "        \n",
    "        for vehicle_idx, vehicle in enumerate(all_vehicles):\n",
    "            v_class = vehicle['class']\n",
    "            v_bbox = vehicle['bbox']\n",
    "            x1, y1, x2, y2 = v_bbox\n",
    "            \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), [0, 255, 0], 2)\n",
    "            cv2.putText(frame, v_class, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, [0, 255, 0], 2)\n",
    "            \n",
    "            # Red light violation - only check if detection is enabled\n",
    "            if ENABLE_RED_LIGHT_DETECTION and red_light_on is True:\n",
    "                in_roi = (cv2.pointPolygonTest(ROI, (x1, y1), False) >= 0 or\n",
    "                         cv2.pointPolygonTest(ROI, (x2, y2), False) >= 0 or\n",
    "                         cv2.pointPolygonTest(ROI, ((x1+x2)//2, (y1+y2)//2), False) >= 0 or\n",
    "                         cv2.pointPolygonTest(ROI, (x1, y2), False) >= 0 or\n",
    "                         cv2.pointPolygonTest(ROI, (x2, y1), False) >= 0)\n",
    "                \n",
    "                if in_roi:\n",
    "                    violations['red_light'].append({'type': v_class, 'bbox': v_bbox})\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), [0, 0, 255], 4)\n",
    "                    draw_text_bg(frame, \"RED LIGHT VIOLATION\", (10, violation_y), border=(0,0,255))\n",
    "                    violation_y += 35\n",
    "            \n",
    "            # Motorcycle checks\n",
    "            if v_class == 'motorcycle' and vehicle_idx not in processed_motorcycles:\n",
    "                processed_motorcycles.add(vehicle_idx)\n",
    "                rider_count, riders = count_riders_on_motorcycle(v_bbox, all_persons)\n",
    "                \n",
    "                if rider_count >= 3:\n",
    "                    violations['triple_riding'].append({'riders': rider_count, 'bbox': v_bbox})\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), [255, 0, 255], 4)\n",
    "                    draw_text_bg(frame, f\"TRIPLE RIDING ({rider_count} riders)\", (10, violation_y), border=(255,0,255))\n",
    "                    violation_y += 35\n",
    "                \n",
    "                if riders:\n",
    "                    for rider_idx, rider_box in enumerate(riders):\n",
    "                        has_helmet = detect_helmet(frame, rider_box, v_bbox)\n",
    "                        if not has_helmet:\n",
    "                            violations['no_helmet'].append({\n",
    "                                'bbox': v_bbox,\n",
    "                                'rider': rider_idx+1,\n",
    "                                'rider_box': rider_box\n",
    "                            })\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), [0, 165, 255], 4)\n",
    "                            rx1, ry1, rx2, ry2 = rider_box\n",
    "                            cv2.rectangle(frame, (rx1, ry1), (rx2, ry2), [255, 255, 0], 3)\n",
    "                            cv2.putText(frame, f\"No Helmet\", (rx1, ry1-5),\n",
    "                                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, [255, 255, 0], 2)\n",
    "                            draw_text_bg(frame, f\"NO HELMET - Rider {rider_idx+1}\", (10, violation_y), border=(0,165,255))\n",
    "                            violation_y += 35\n",
    "            \n",
    "            # Number plate detection - show only if detected or generate if not found\n",
    "            if v_class in ['car', 'bus', 'truck', 'motorcycle']:\n",
    "                plate_info = detect_number_plate(frame, v_bbox)\n",
    "                \n",
    "                if plate_info['detected'] and plate_info['text']:\n",
    "                    # Real plate detected - show in GREEN\n",
    "                    plate_text = plate_info['text']\n",
    "                    confidence = plate_info.get('confidence', 0)\n",
    "                    cv2.putText(frame, f\"Plate: {plate_text} ({confidence:.2f})\", (x1, y2+20),\n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, [0, 255, 0], 2)\n",
    "                else:\n",
    "                    # No plate detected - mark as violation and generate random\n",
    "                    plate_text = generate_random_plate()\n",
    "                    violations['no_number_plate'].append({\n",
    "                        'type': v_class, \n",
    "                        'bbox': v_bbox,\n",
    "                        'generated_plate': plate_text\n",
    "                    })\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), [255, 165, 0], 3)\n",
    "                    cv2.putText(frame, f\"No Plate (Gen: {plate_text})\", (x1, y2+20),\n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, [255, 165, 0], 2)\n",
    "                    draw_text_bg(frame, f\"NO PLATE - Generated: {plate_text}\", (10, violation_y), \n",
    "                               border=(255,165,0))\n",
    "                    violation_y += 35\n",
    "        \n",
    "        # Signal indicator - only if detection is enabled\n",
    "        if ENABLE_RED_LIGHT_DETECTION and red_light_on is not None:\n",
    "            signal_color = \"RED\" if red_light_on else \"GREEN\"\n",
    "            signal_bg = (0, 0, 255) if red_light_on else (0, 255, 0)\n",
    "            cv2.rectangle(frame, (frame.shape[1]-200, 10), (frame.shape[1]-10, 50), signal_bg, -1)\n",
    "            cv2.putText(frame, f\"Signal: {signal_color}\", (frame.shape[1]-190, 35),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        output_path = f'output_images/{os.path.basename(img_path)}'\n",
    "        cv2.imwrite(output_path, frame)\n",
    "        \n",
    "        total = sum(len(v) for v in violations.values())\n",
    "        \n",
    "        result = {\n",
    "            'image': img_path,\n",
    "            'output': output_path,\n",
    "            'red_light_on': 'DISABLED' if not ENABLE_RED_LIGHT_DETECTION else (red_light_on if red_light_on is not None else 'N/A'),\n",
    "            'total_violations': total,\n",
    "            'violations': violations,\n",
    "            'vehicle_count': len(all_vehicles),\n",
    "            'person_count': len(all_persons),\n",
    "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        all_results.append(result)\n",
    "        \n",
    "        if not ENABLE_RED_LIGHT_DETECTION:\n",
    "            print(f\"  Signal: ‚ö†Ô∏è  DISABLED\")\n",
    "        elif red_light_on is None:\n",
    "            print(f\"  Signal: ‚ö™ NO TRAFFIC LIGHT\")\n",
    "        else:\n",
    "            print(f\"  Signal: {'üî¥ RED' if red_light_on else 'üü¢ GREEN'}\")\n",
    "        print(f\"  Detected: {len(all_vehicles)} vehicles, {len(all_persons)} persons\")\n",
    "        print(f\"  Total Violations: {total}\")\n",
    "        if violations['red_light']:\n",
    "            print(f\"    üî¥ Red Light: {len(violations['red_light'])}\")\n",
    "        if violations['no_helmet']:\n",
    "            print(f\"    ü™ñ No Helmet: {len(violations['no_helmet'])}\")\n",
    "        if violations['triple_riding']:\n",
    "            print(f\"    üë• Triple Riding: {len(violations['triple_riding'])}\")\n",
    "        if violations['no_number_plate']:\n",
    "            print(f\"    üö´ No Plate (Generated): {len(violations['no_number_plate'])}\")\n",
    "    \n",
    "    with open('output_images/violations_report.json', 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\n‚úÖ Processing complete!\")\n",
    "    print(f\"üìä Total images processed: {len(image_files)}\")\n",
    "    print(f\"üö® Total violations found: {sum(r['total_violations'] for r in all_results)}\")\n",
    "    print(f\"üìÅ Results saved in 'output_images/' folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061458d4",
   "metadata": {},
   "source": [
    "## 7. Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279841fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüì∏ RESULTS GALLERY\\n\" + \"=\"*70)\n",
    "\n",
    "for i, result in enumerate(all_results, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Image {i}: {os.path.basename(result['image'])}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    display(HTML(f'''\n",
    "    <div style=\"display: flex; gap: 10px; margin: 20px 0;\">\n",
    "        <div style=\"flex: 1;\">\n",
    "            <h4>Original</h4>\n",
    "            <img src=\"{result['image']}\" style=\"width: 100%; border: 2px solid #ddd;\">\n",
    "        </div>\n",
    "        <div style=\"flex: 1;\">\n",
    "            <h4>Detected ({result['total_violations']} violations)</h4>\n",
    "            <img src=\"{result['output']}\" style=\"width: 100%; border: 3px solid {'red' if result['total_violations'] > 0 else 'green'};\">\n",
    "        </div>\n",
    "    </div>\n",
    "    '''))\n",
    "    \n",
    "    v = result['violations']\n",
    "    if result['total_violations'] > 0:\n",
    "        print(\"‚ö†Ô∏è Violations Found:\")\n",
    "        if v['red_light']: print(f\"  üî¥ Red Light: {len(v['red_light'])}\")\n",
    "        if v['no_helmet']: print(f\"  ü™ñ No Helmet: {len(v['no_helmet'])}\")\n",
    "        if v['triple_riding']: print(f\"  üë• Triple Riding: {len(v['triple_riding'])}\")\n",
    "        if v['no_number_plate']: print(f\"  üö´ No Number Plate: {len(v['no_number_plate'])}\")\n",
    "    else:\n",
    "        print(\"‚úÖ No violations detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81315d7d",
   "metadata": {},
   "source": [
    "## 8. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8d2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Check if running in Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(\"üì¶ Creating download package...\")\n",
    "shutil.make_archive('complete_violation_results', 'zip', 'output_images')\n",
    "print(\"‚úÖ Package ready!\\n\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"üì• Downloading results...\")\n",
    "    files.download('complete_violation_results.zip')\n",
    "    files.download('output_images/violations_report.json')\n",
    "    print(\"‚úÖ Downloads started! Check your browser.\")\n",
    "else:\n",
    "    print(\"üìÅ Results saved as 'complete_violation_results.zip'\")\n",
    "    print(\"üìÑ JSON report: 'output_images/violations_report.json'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
